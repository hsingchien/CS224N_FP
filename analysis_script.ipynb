{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, numpy as np, argparse\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from bert import BertModel\n",
    "from optimizer import AdamW\n",
    "from tqdm import tqdm\n",
    "from datasets import (\n",
    "    SentenceClassificationDataset,\n",
    "    SentenceClassificationTestDataset,\n",
    "    SentencePairDataset,\n",
    "    SentencePairTestDataset,\n",
    "    load_multitask_data,\n",
    ")\n",
    "\n",
    "from evaluation import (\n",
    "    model_eval_sst,\n",
    "    model_eval_multitask,\n",
    "    model_eval_test_multitask,\n",
    "    model_val_sts,\n",
    "    model_val_para,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "sst_train, sst_dev = \"data/ids-sst-train.csv\", \"data/ids-sst-dev.csv\"\n",
    "para_train, para_dev = \"data/quora-train.csv\", \"data/quora-dev.csv\"\n",
    "sts_train, sts_dev = \"data/sts-train.csv\", \"data/sts-dev.csv\"\n",
    "\n",
    "\n",
    "sst_train_data, num_labels, para_train_data, sts_train_data = load_multitask_data(\n",
    "    sst_train, para_train, sts_train, split=\"train\"\n",
    ")\n",
    "sst_dev_data, num_labels, para_dev_data, sts_dev_data = load_multitask_data(\n",
    "    sst_dev, para_dev, sts_dev, split=\"dev\"\n",
    ")\n",
    "\n",
    "sst_train_data = SentenceClassificationDataset(sst_train_data, None)\n",
    "sst_dev_data = SentenceClassificationDataset(sst_dev_data, None)\n",
    "\n",
    "\n",
    "sst_train_dataloader = DataLoader(\n",
    "    sst_train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=8,\n",
    "    collate_fn=sst_train_data.collate_fn,\n",
    ")\n",
    "sst_dev_dataloader = DataLoader(\n",
    "    sst_dev_data,\n",
    "    shuffle=False,\n",
    "    batch_size=8,\n",
    "    collate_fn=sst_dev_data.collate_fn,\n",
    ")\n",
    "\n",
    "para_train_data = SentencePairDataset(para_train_data, None)\n",
    "para_dev_data = SentencePairDataset(para_dev_data, None)\n",
    "\n",
    "para_train_dataloader = DataLoader(\n",
    "    para_train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    collate_fn=para_train_data.collate_fn,\n",
    ")\n",
    "para_dev_dataloader = DataLoader(\n",
    "    para_dev_data,\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    "    collate_fn=para_dev_data.collate_fn,\n",
    ")\n",
    "\n",
    "sts_train_data = SentencePairDataset(sts_train_data, None, isRegression=True)\n",
    "sts_dev_data = SentencePairDataset(sts_dev_data, None, isRegression=True)\n",
    "\n",
    "sts_train_dataloader = DataLoader(\n",
    "    sts_train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=8,\n",
    "    collate_fn=sts_train_data.collate_fn,\n",
    ")\n",
    "sts_dev_dataloader = DataLoader(\n",
    "    sts_dev_data,\n",
    "    shuffle=False,\n",
    "    batch_size=8,\n",
    "    collate_fn=sts_dev_data.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "from multitask_classifier import MultitaskBERT\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(f\"cuda:0\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "config = SimpleNamespace(\n",
    "    **{\n",
    "        \"hidden_dropout_prob\": 0.3,\n",
    "        \"num_labels\": num_labels,\n",
    "        \"hidden_size\": 768,\n",
    "        \"data_dir\": \".\",\n",
    "        \"fine_tune_mode\": \"full-model\",\n",
    "    }\n",
    ")\n",
    "# model_path = (\n",
    "#     \"./predictions/single_task_model/single_sts/full-model-20-1e-05-multitask.pt\"\n",
    "# )\n",
    "model_path = \"\"\n",
    "model = MultitaskBERT(config)\n",
    "if model_path:\n",
    "    saved = torch.load(model_path, map_location=device)\n",
    "    config = saved[\"model_config\"]\n",
    "    model.load_state_dict(saved[\"model\"])\n",
    "    print(f\"using fine-tuned BERT in {device}!\")\n",
    "else:\n",
    "    print(f\"using pretrained NOT fine-tuned base BERT in {device}!\")\n",
    "\n",
    "model = model.to(device)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"model has {total_params} parameters!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and generate list of cls embeddings and avg tken embedding\n",
    "import pandas as pd\n",
    "\n",
    "sst_dataloader, para_dataloader, sts_dataloader = (\n",
    "    sst_dev_dataloader,\n",
    "    para_dev_dataloader,\n",
    "    sts_dev_dataloader,\n",
    ")\n",
    "sts_cos_df = pd.DataFrame(\n",
    "    index=range(len(sts_dev_data)), columns=[\"id\", \"label\", \"cls_cos\", \"avg_cos\"]\n",
    ")\n",
    "sts_cos_df[\"label\"].astype(np.float16)\n",
    "ridx = 0\n",
    "for batch in tqdm(sts_dataloader):\n",
    "    tk_id1 = batch[\"token_ids_1\"].to(device)\n",
    "    at_msk1 = batch[\"attention_mask_1\"].to(device)\n",
    "    tken_type_ids_1 = batch[\"token_type_ids_1\"].to(device)\n",
    "    tk_id2 = batch[\"token_ids_2\"].to(device)\n",
    "    at_msk2 = batch[\"attention_mask_2\"].to(device)\n",
    "    tken_type_ids_2 = batch[\"token_type_ids_2\"].to(device)\n",
    "    labels = batch[\"labels\"].float().to(device)\n",
    "    sents_id = batch[\"sent_ids\"]\n",
    "    btch_sz = tk_id1.shape[0]\n",
    "    # get the embeddings\n",
    "    sent1_cls, sent1_avg = model.forward(tk_id1, at_msk1)\n",
    "    sent2_cls, sent2_avg = model.forward(tk_id2, at_msk2)\n",
    "\n",
    "    cls_cos = F.cosine_similarity(sent1_cls, sent2_cls)\n",
    "    avg_cos = F.cosine_similarity(sent1_avg, sent2_avg)\n",
    "    sts_cos_df.iloc[ridx : ridx + btch_sz, 2:4] = np.concatenate(\n",
    "        (\n",
    "            cls_cos.detach().cpu().numpy()[:, np.newaxis],\n",
    "            avg_cos.detach().cpu().numpy()[:, np.newaxis],\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    sts_cos_df.iloc[ridx : ridx + btch_sz, 0] = sents_id\n",
    "    sts_cos_df.iloc[ridx : ridx + btch_sz, 1] = labels.cpu()\n",
    "    ridx += btch_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the df\n",
    "# sgl_sts_BERT_sts_df = sts_cos_df.copy()\n",
    "pretr_BERT_sts_df = sts_cos_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some visualization of pretrained BERT\n",
    "import seaborn as ses\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sgl_sts_BERT_sts_df[\"label_cat\"] = sgl_sts_BERT_sts_df[\"label\"].astype(int)\n",
    "pretr_BERT_sts_df[\"label_cat\"] = pretr_BERT_sts_df[\"label\"].astype(int)\n",
    "xl = (-0.5, 5.5)\n",
    "f = plt.figure(figsize=(10, 10))\n",
    "plt.subplot(3, 1, 1)\n",
    "ax = ses.histplot(pretr_BERT_sts_df[\"label\"], bins=25, color=\"tab:orange\")\n",
    "ax.set_xlim(xl)\n",
    "ax.set_xticks(range(6))\n",
    "plt.subplot(3, 2, 3)\n",
    "ax = ses.histplot(pretr_BERT_sts_df[\"cls_cos\"] * 5, bins=25, color=\"tab:green\")\n",
    "ax.set_xlim(xl)\n",
    "ax.set_xticks(range(6))\n",
    "plt.subplot(3, 2, 4)\n",
    "ax = ses.histplot(pretr_BERT_sts_df[\"avg_cos\"] * 5, bins=25, color=\"tab:blue\")\n",
    "ax.set_xlim(xl)\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_xticks(range(6))\n",
    "plt.subplot(3, 2, 5)\n",
    "ax = ses.histplot(sgl_sts_BERT_sts_df[\"cls_cos\"] * 5, bins=25, color=\"tab:green\")\n",
    "ax.set_xlim(xl)\n",
    "ax.set_xticks(range(6))\n",
    "plt.subplot(3, 2, 6)\n",
    "ax = ses.histplot(sgl_sts_BERT_sts_df[\"avg_cos\"] * 5, bins=25, color=\"tab:blue\")\n",
    "ax.set_xlim(xl)\n",
    "ax.set_xticks(range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the cos and bins into a summary df\n",
    "# plot bar plot along cosine axis, for each model output\n",
    "f, ax = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "f1 = ses.scatterplot(\n",
    "    data=pretr_BERT_sts_df, x=\"label\", y=\"cls_cos\", hue=\"label_cat\", ax=ax[0, 0]\n",
    ")\n",
    "f1.get_legend().set_visible(False)\n",
    "f1.set_xlim(xl)\n",
    "f1.set_xticks(range(6))\n",
    "f2 = ses.scatterplot(\n",
    "    data=pretr_BERT_sts_df, x=\"label\", y=\"avg_cos\", hue=\"label_cat\", ax=ax[0, 1]\n",
    ")\n",
    "f2.get_legend().set_visible(False)\n",
    "f2.set_xlim(xl)\n",
    "f2.set_xticks(range(6))\n",
    "f3 = ses.scatterplot(\n",
    "    data=sgl_sts_BERT_sts_df, x=\"label\", y=\"cls_cos\", hue=\"label_cat\", ax=ax[1, 0]\n",
    ")\n",
    "f3.get_legend().set_visible(False)\n",
    "f3.set_xlim(xl)\n",
    "f3.set_xticks(range(6))\n",
    "f4 = ses.scatterplot(\n",
    "    data=sgl_sts_BERT_sts_df, x=\"label\", y=\"avg_cos\", hue=\"label_cat\", ax=ax[1, 1]\n",
    ")\n",
    "f4.get_legend().set_visible(False)\n",
    "f4.set_xlim(xl)\n",
    "f4.set_xticks(range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the delta cos similarity\n",
    "sgl_sts_BERT_sts_df[\"dcos_cls\"] = (\n",
    "    sgl_sts_BERT_sts_df[\"cls_cos\"] - pretr_BERT_sts_df[\"cls_cos\"]\n",
    ")\n",
    "sgl_sts_BERT_sts_df[\"dcos_avg\"] = (\n",
    "    sgl_sts_BERT_sts_df[\"avg_cos\"] - pretr_BERT_sts_df[\"avg_cos\"]\n",
    ")\n",
    "\n",
    "f, ax = plt.subplots(nrows=2, ncols=1, figsize=(6, 8))\n",
    "f1 = ses.histplot(\n",
    "    data=sgl_sts_BERT_sts_df, x=\"dcos_cls\", hue=\"label_cat\", ax=ax[0], bins=25\n",
    ")\n",
    "# f1.get_legend().set_visible(False)\n",
    "f1.set_xlim((-1.2, 1.2))\n",
    "f1 = ses.histplot(\n",
    "    data=sgl_sts_BERT_sts_df, x=\"dcos_avg\", hue=\"label_cat\", ax=ax[1], bins=25\n",
    ")\n",
    "f1.set_xlim((-1.2, 1.2))\n",
    "# f1.get_legend().set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n_dfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
